* Lagrangian Duality

Following Chapter 5 of Convex Optimization.

** Definitions

All problems will be assumed in *standard form*. For some \[x\in\mathbb{R}^n\]

\[\min f_0(x)\,\mathrm{s.t.}\,\forall i\in[m]\,f_i(x)\le 0\,,\forall j\in[p] \,h_j(x)=0\]

I.e., \[f_0\] is the objective, we have \[m\] inequality constraints, and \[p\] equality constraints.

The domain for the problem \[\mathcal{D}\] is the set on which all of these functions are defined. Note
this is distinct from the feasible, set, which restricts \[\mathcal{D}\] further to the set of points
matching the inequality and equality constraints.

Note the problem need not be convex.

The *Lagrangian function* for a standard form mathematical program. It is defined as a function \[L:\mathbb{R}^n\times\mathbb{R}^m\times \mathbb{R}^p\rightarrow\mathbb{R}\] as
\[L(x, \lambda, \nu)=f_0(x)+\lambda^\top f(x)+\nu^\top h(x)\], viewing \[f,h\] as vector-valued functions over the
inequality and equality constraints, respectively.

The Lagrangian *dual function* is just \[g(\lambda, \nu)=\inf_x L(x, \lambda, \nu)\] with inputs \[\mathrm{R}^m\times\mathbb{R}^p\]
and technically taking values over \[-\infty, \mathbb{R}\] for nonempty \[\mathcal{D}\].

Regardless of the convexity of the original problem, by the linear dependence of \[L\] on \[\lambda,\nu\],
as an infimum of affine functions \[g\] is always concave.

** Lagrangian as Linear Constraint Relaxation

Notice that \[U=\min f_0(x)+\sum_i I_{-}\circ f_i(x)+\sum_i I_{0}\circ h_j(x)\] is identical to
the original standard form program, where \[I_{-}(u)=\begin{cases}0 &u<0\\\infty &\text{o/w}\end{cases}\] and \[I_0\] is analogous for \[0\].

This unconstrained equivalent program can be relaxed with linear constraints. For \[\lambda_i\ge 0\],
\[\lambda_i f_i(x)<I_{-}\circ f_i(x)\] for feasible \[x\], as \[f_i\le 0\] when feasible. And for all \[\nu_j\] and feasible \[x\], \[\nu_j h_j(x)\le I_0\circ h_j(x)\].

Thus a Lagrange function can be viewed as a linear relaxation of constraints encoded
in the objective. Taking the infimum over all \[x\in\mathcal{D}\] then also gives us
weak duality, namely if the solution to the original standard form program is \[p^*\] that
\[g(\lambda, \nu)\le U=p^*\] for \[\lambda>0\]. Taking a supremum over the dual function arguments
is *weak duality*.

** Weak Duality

Weak duality is the fact that \[d^*\le p^*\], always, for the dual program \[d^*=\sup g(\lambda, \nu)\] over
dual feasible points \[\lambda\ge 0,\nu\in\mathbb{R}^p\].

This follows per the reasoning above.

It also means that we can get *certificates*, which are dual feasible solutions \[\tilde\lambda, \tilde\nu\]
that the lower bound \[p^*\] with \[g(\tilde\lambda, \tilde \nu)\].

Such certificates are helpful when the original problem (the *primal problem* is tough to solve,
in which case we can propose guesses for approximate solutions, e.g., with random search, and then
just check how close they are to the optimal solution). If the *duality gap* \[p^*-d^*\] is small
and we have a good certificate then \[g(\tilde\lambda,\tilde\nu)\approx d^*\approx p^*\] (where left to right the values increase)
so we can use \[f_0(x)-g(\tilde\lambda,\tilde\nu)\] as a proxy upper bound for how close we are to
optimality in practice.

** The Dual Problem
The dual function, by virtue of being an infimum, can frequently be written as \[g(\lambda,\nu)=\begin{cases} h(\lambda,\nu) & (\lambda,\nu)\in S\\
-\infty & \text{o/w}\end{cases}\]
for some set \[S\] by solving the \[\inf\] analytically. Often in such situations,
\[S\] is isomorphic under \[\phi\] to a space \[S'\] of much lower dimension than \[m+p\]. In that case, we can view
a *Lagrangian dual problem* to our original primal program as the program \[\max_{y\in S'} h\circ\phi^{-1}(y)\].

Computationally, this may be advantageous. Note now we can still view \[y\in S'\] as feasible and thus
certificates because mathematically we are maximizing a lower bound.

Note that this /modified/ Lagrangian dual problem, /may or may not/ be convex. Even though
the Lagrangian dual /function/ is always concave, on the lower-dimensional manifold we might cast
the dual problem in may no longer be convex. As an example of this is visible by taking the trust 
region problem below, a non-convex program with strong duality and a convex dual.

Going /the other way/, from the convex dual, recovers a Lagrangian which can be modified to recover
the original primal.

** Strong Duality

Strong Duality holds when \[d^*=p^*\].

Often, but not always, strong duality holds for convex problems, where \[f_0, f_i\] and optimization domain
are convex.

Things can be similarly variable for non-convex problems, though those often fail to have strong duality.

Note some gotchas (see [[Examples]])
 - Convex doesn't imply efficiency, which is a structural property of \[f_0,f_i,h_j\].
 - Convex and strong duality don't always go hand-in-hand.

To the first point, note that any problem can easily be made convex: simply
define a new variable and constraint \[f_0(x)\le \gamma\] and minimize \[\gamma\].

As an affine objective, its optimum is unchanged if we replace the feasible set
with its convex hull. This yields an equivalent program with the same optimal
value that's convex. One can recover decision variables with a bisection routine
on top of this widened set (up to a certain precision), in polynomial time.

** Geometric Interpretation

The Geometric Interpretation surfaces much intuition about the dual problem (see [[geometric.pdf][Geometric]] notes):

 - The dual is /structurally/ tied to the primal. Notice how programs \[(f_0,f_i,h_j)\] and \[(f_0, 1\land f_i,h_j)\] have identical feasible sets and primal optima. However, their duals are very different. /A dual relies on constraint function values outside the feasible set/.
 - The above fact can be of computational interest: it means to solve a primal we can use dual information about "how much a constraint is broken".
 - *Complimentary slackness*, that \[\lambda_i^*f_i*(x^*)=0\] at optimality, follows from geometry
 - *Slater's Constraint Qualification*, that for convex programs if there is any strictly feasible point \[x\in\mathrm{relint} \mathcal{D}\] with \[f_i(x)<0\] for nonlinear \[f_i\], then strong duality holds, follows from geometry.

** Convex Conjugates

Convex conjugates are a core concept in Fenchel duality, which describe a function in terms of its
supporting hyperplanes.

Consider a function \[f\] and a slope \[m\]. Following [[https://math.stackexchange.com/questions/223235/please-explain-the-intuition-behind-the-dual-problem-in-optimization/624633#624633][this SO answer]], suppose for some intercept \[\alpha\]
the hyperplane \[\langle m,  x\rangle -\alpha\le f(x)\] is dominated by \[f\]. Here the intercept tells us exactly how much
the homogenous plane \[\langle m, x\rangle \] must be downshifted to support \[f\]. We can thus
compute the smallest such shift (such that the hyperplane supports \[f\]) by rearranging and
taking a supremum, \[\alpha \ge \sup_x \langle m, x\rangle - f(x)=\alpha^*\], say.

This is the convex conjugate: \[f^*(m)=\alpha^*\].

This is also known as the Fenchel transformation. As a supremum of affine functions, the convex
conjugate is always itself convex, regardless of the convexity of \[f\].

From this intuitive perspective, \[f^*\] characterizes the /epigraph/ of \[f\] through its
supporting hyperplanes. For /convex/ functions \[f\], their epigraph is itself convex and thus
characterized by the intersection of supporting half-spaces.

This can lead us to a (convex-only) view of strong duality,
described below in the [[Involution and Fenchel Duality]] section.

Even beyond their use as theoretical instruments, convex conjugates show up naturally in deriving
Lagrangian dual problems with linear constraints. This is because the Lagrangian of 

\[\min_x f_0(x) \,\text{s.t.}\, A x\le b\,,\, Cx=d\]

is given by 

\[g(\lambda, \nu)=\inf_x f_0(x)+\lambda^\top (Ax -b)+\nu ^\top (Cx-d)=-b^\top\lambda -d^\top \nu -f_0^*(-A^\top \lambda - C^\top \nu)\]

See [[Examples]] of Lasso and SVM. Note that the above can also manifest when the objective or constraints
are of the form \[f_i(Ax-b)\] in which case introducing a new variable exposes structure of the constraints
into the problem, giving rise to new conjugates appearing in the dual (and possibly a more useful dual).

Useful links for convex conjugates

 - [[http://www.seas.ucla.edu/~vandenbe/236C/lectures/conj.pdf][Conjugate Construction Rules]]
 - [[https://math.stackexchange.com/questions/3706312/convex-conjugate-of-composition-with-non-invertible-linear-transform][Convex Conjugate Composition]], [[http://archive.control.lth.se/media/Education/DoctorateProgram/2015/LargeScaleConvexOptimization/Lectures/conj_fcn.pdf][in depth]]
 - [[http://niaohe.ise.illinois.edu/IE521/IE521-lecture-7-convex%20conjuate.pdf][More examples]]

** Examples

See the following PDF files for worked examples of dual problems derived from primal ones.
 - [[http://www.princeton.edu/~aaa/Public/Teaching/ORF523/ORF523_Lec5.pdf][Linear Programs]], convex with strong dual (notably, linear programs are always strongly dual, except when both [[https://en.wikipedia.org/wiki/Dual_linear_program#Infeasible_program][primal and dual]] are infeasible).
 - [[https://www.di.ens.fr/~aspremon/PDF/MVA/ApplicationsOne.pdf][Two-Way Partition]] a non-convex primal with a weak and convex dual problem
 - [[https://doi.org/10.1137/0805016][Trust Region]], a non-convex problem with a strong dual
 - [[svm.pdf][SVM]], a classic convex QP example where duality provides possible speedup through the kernel trick.
 - [[lasso.pdf][Lasso]], which admits two distinct duals, similar to these [[https://www.cs.ubc.ca/~schmidtm/Documents/2008_Notes_LassoDual.pdf][online notes]], but consider more general cases and don't drop constants between primal/dual.
 - an example of a convex problem without strong duality is in the [[geometric.pdf][Geometric]] notes.
 - Last section of these [[https://www.cse.iitk.ac.in/users/rmittal/prev_course/s14/notes/lec16.pdf][IIT notes]] gives two jointly dual problems with a nonzero duality gap.

** KKT Optimality Conditions

For problems which are possibly non-convex but differentiable, the smooth KKT conditions on a primal \[x^*\]
point and its duals \[\lambda^*,\nu^*\] are:

1. primal feasibility \[f_i(x^*)\le 0,h_j(x^*)=0\].
2. dual feasibility \[\lambda_i^*\ge 0\]
3. complementary slackness \[\lambda_i^*x_i^*=0\]
4. stationarity \[\nabla_{x}L(x,\lambda^*,\nu^*)\big|_{x=x^*}=0\]

In this setting, strong duality implies that the optimum must meet the smooth KKT conditions:
\[\mathrm{SD}\implies(\mathrm{opt\ at}\ x^*\implies\mathrm{smooth\ KKT\ at}\ x^*)\]

For convex problems, we instead have access only to the subgradient \[\partial L\], which replaces
the \[\nabla\] yielding a set-like stationarity condition \[0\in\partial(x\mapsto L(x,\lambda^*, \nu^*))\].

However, with convex problems, we have a stronger relationship:
\[\mathrm{SD}\implies (\mathrm{opt\ at}x^*\iff\mathrm{cvx\ KKT\ at}x^*)\]

Note bidirectionality here.

** Sensitivity Analysis

The perturbed problem of our original standard form problem is
\[\min f_0(x)\,\mathrm{s.t.}\,\forall i\in[m]\,f_i(x)\le u_i\,,\forall j\in[p] \,h_j(x)=v_j \]


We can define the optimum under the above perturbations \[(u, v)\] as \[p^*(u,v)\].

When the original problem is convex so is \[p^*\].

*** Global Sensitivity Inequality

Under strong duality, assuming the dual optimum is attained, we have a global sensitivity inequality
\[p^*(u,v)\ge p^*(0,0)-\langle \lambda^*, u\rangle-\langle \nu^*, v\rangle\], which follows from expansion
of the Lagrangian, strong duality, and the definition of the dual.

Note that this provides a clean interpretation of the Lagrangian parameters (but they always go
in "worse" directions; i.e., you never get to find out when \[p^*\] improves by getting lower.

For example, if \[\lambda_i^*\] is large and we tighten \[u_i\] by lowering it to a negative value,
then \[p^*\] will increase significantly. On the other hand, if \[\lambda_i^*\] is small and
we loosen \[u_i\] by increasing it we won't improve \[p^*\] by much; however, the vice-versa statements
do not hold. We cannot with confidence say when \[p^*\] will improve by much.

*** Local Sensitivity

When \[p^*(u,v)\] is differentiable (which does not happen often and is not merely a consequence of
differentiability of a standard form problem), then we have equalities
\[\lambda_i^*=-\partial_{u_i}p^*(u,v)\big|_{(u,v)=0},\nu_i^*=-\partial_{v_i}p^*(u,v)\big|_{(u,v)=0}\]. In this differentiable case we do have that locally \[p^*\] has
slope given by its Lagrange multiplier. This does give us at least local guaranteed decrease in \[p^*\]
when loosening the problem (and a guarantee of non-increase for small Lagrange multipliers).

** Implicit Constraints

Sometimes, constraints can be encoded implicitly, i.e., replacing \[f_0\] with \[f_0(x) + \begin{cases}0&f_i(x)\le 0\\\infty & \text{o/w}\end{cases}\]
to get rid of the \[i\]-th constraint. This is useful when the corresponding dual infimum \[\inf_{f_i\le0}f_0\]
can be solved analytically, allowing for partial analytic knowledge to be encoded into the dual.

** Theorems of Alternatives

Consider the primal system of inequalities \[\{f_i(x)\le 0|i\in[m]\}\]. If there exists a linear combination
of the constraints such that the infimum is strictly positive, i.e., \[\exists \lambda\ge 0\,g(\lambda)=\inf_x\lambda^\top f(x)>0\],
then the latter statement /certifies/ that the primal system is infeasible; for if they
 were the inf of the linear sum would not be strictly positive. Conversely, the existence of
a feasible primal \[x\] implies non-positivity for any \[\lambda\ge 0\] of the dual.

The above presents us with _weak alternatives_: at most one of the two systems are feasible.

We can also consider stronger assumptions that yield _strong alternatives_: exactly one of the two
systems must be feasible. For instance, by adding a Slater-type condition to the above, it can become
a system of strong alternatives. The proof in the book skipped a step, see my notes [[strong-alternatives.pdf][Strong Alternatives]].

We can view such Theorems of Alternatives about feasibility as a form of duality in a geometric setting.

** Involution and Fenchel Duality

One frustrating thing in all of the above discussion is that there isn't a satisfying notion of what
"the" dual for a problem is.

We've seen that duality is a structural property of a program per the bullet in [[Geometric Interpretation]].

What this means is that it's not sensible to ask, abstractly, for the dual optimization over a set,
e.g., \[\min_{x\in C} f(x)\]. This is equivalent to unconstrained \[\min f'\], extending \[f'=f+\delta_C\] where \[\delta_C(x)=\begin{cases}0&x\in C\\\infty & \text{o/w}\end{cases}\] .
Clearly this purely functional interpretation of optimization is missing some piece of duality.
Let's call such formulations "narrow programs".

Indeed, a dual only emerges when we specify a perturbation function \[\phi(x, y)\], which
satisfies \[\phi(x, 0)=f'(x)\], but otherwise \[\phi\] is free. Then the interpretation of \[y\]
is as a perturbation of our constraints. It specifies the degree of slack we need for the constraints
to be met, and in turn provides a geometry for the dual space. 

Thus, for the same narrow program we can specify multiple perturbations (equivalently, characterizations
oft he constraint set) and thus multiple duals.

For \[\phi\] defined over topologically regular spaces, [[https://en.wikipedia.org/wiki/Fenchel%E2%80%93Moreau_theorem][Fenchel–Moreau theorem]] characterizes
when the dual of the dual is the primal, which is the involutive property that makes
the primal and dual true mirrors of one another. This also implies strong duality,
by using both sides of the weak dual. [[https://en.wikipedia.org/wiki/Duality_gap][Duality gap]].

Notably, involution characterizes convex strong duality.

 - [[https://math.stackexchange.com/questions/948862/fenchel-dual-vs-lagrange-dual][Fenchel Dual vs Lagrange Dual]]
 - [[https://math.stackexchange.com/a/624633/38471][Dual problem via supporting hyperplanes]]

All of this is to say when people talk about "the" dual for an optimization problem,
they're talking about the one implied by adding slack variables to some sort of general
inequality that their current program uses (thus implicitly defining a perturbation function).

For instance the [[https://en.wikipedia.org/wiki/Semidefinite_programming][SDP]] has positive-semidefinite inequalities \[X\succeq 0\] which admit natural perturbations
\[X+Y\succeq 0\]. In principle, we could rewrite the SDP in dot-product form, possibly changing the dual
because of different perturbations.

The most abstract form of such inequalities I'm aware of is generic [[https://math.stackexchange.com/a/2287265/38471][convex cone]] partial inequalities,
so anything of this form can get duals generated "easily".

Section 5.9 recounts all of the above; it generalizes naturally the aforementioned Lagrangian duality.
Even Slater's condition holds. The only caveat is that complimentary slackness for a general conic
constraint \[f_i(x)\preceq_{K_i}0\] where \[K_i\] is a proper cone and \[x\succeq_K y\] implies \[x-y\in K\] for a cone \[K\]
(since \[x\] is "bigger" than \[y\] in the "cone's direction")  where now \[\lambda_i^*\in K_i^*\], the dual cone
having \[\langle \lambda_i^*, f_i(x)\rangle =0\] at optimality. This orthogonality condition does not imply that one is zero if the other is.

Similar KKT conditions can be derived without too much modification.
